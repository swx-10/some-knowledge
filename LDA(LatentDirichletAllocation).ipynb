{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA是一种文档主题生成模型，也成为三层贝叶斯概率模型，包含词、主题和文档三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程。文档到主题服从多项式分布，主题到词服从多项式分布。LDA的目的就是要识别主题，即把文档-词汇矩阵变成文档-主题矩阵（分布）和主题-词汇矩阵（分布）。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入文本数据\n",
    "doc = [\"空中命脉已被掐断 陆地运输难度加大，揭秘西方军援乌克兰通道\",\n",
    "       \"美国总统拜登宣布向乌克兰提供8亿美元额外军事援助\",\n",
    "       \"解放军和武警部队代表团新闻发言人：对“台独”绝不姑息 露头就打\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\80665\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.464 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['空中',\n",
       "  '命脉',\n",
       "  '已',\n",
       "  '被',\n",
       "  '掐断',\n",
       "  ' ',\n",
       "  '陆地',\n",
       "  '运输',\n",
       "  '难度',\n",
       "  '加大',\n",
       "  '，',\n",
       "  '揭秘',\n",
       "  '西方',\n",
       "  '军援',\n",
       "  '乌克兰',\n",
       "  '通道'],\n",
       " ['美国', '总统', '拜登', '宣布', '向', '乌克兰', '提供', '8', '亿美元', '额外', '军事援助'],\n",
       " ['解放军',\n",
       "  '和',\n",
       "  '武警部队',\n",
       "  '代表团',\n",
       "  '新闻',\n",
       "  '发言人',\n",
       "  '：',\n",
       "  '对',\n",
       "  '“',\n",
       "  '台独',\n",
       "  '”',\n",
       "  '绝不',\n",
       "  '姑息',\n",
       "  ' ',\n",
       "  '露头',\n",
       "  '就',\n",
       "  '打']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分词\n",
    "doc = [jieba.lcut(x) for x in doc]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['空中', '命脉', '掐断', '陆地', '运输', '难度', '加大', '揭秘', '西方', '军援', '乌克兰', '通道'], ['美国', '总统', '拜登', '乌克兰', '提供', '亿美元', '额外', '军事援助'], ['解放军', '武警部队', '代表团', '新闻', '发言人', '台独', '姑息', '露头']]\n"
     ]
    }
   ],
   "source": [
    "#去停用词\n",
    "sw = \"./stop_word.txt\"\n",
    "stop_word = []\n",
    "with open(sw, 'r', encoding='utf-8') as f:\n",
    "    for l in f:\n",
    "        l = l.strip()\n",
    "        stop_word.append(l)\n",
    "new_doc = []\n",
    "for sentence in doc:\n",
    "    new_s = []\n",
    "    for w in sentence:\n",
    "        if w not in stop_word and w != ' ':\n",
    "            new_s.append(w)\n",
    "    new_doc.append(new_s)\n",
    "print(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)], [(0, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)], [(19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#文本向量化\n",
    "dictionary = corpora.Dictionary(new_doc)\n",
    "DT = [dictionary.doc2bow(s) for s in new_doc]\n",
    "print(DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(DT, num_topics=2, id2word=dictionary, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.070*\"姑息\" + 0.070*\"新闻\" + 0.070*\"发言人\" + 0.070*\"露头\" + 0.070*\"代表团\"'), (1, '0.075*\"乌克兰\" + 0.045*\"揭秘\" + 0.045*\"陆地\" + 0.045*\"通道\" + 0.045*\"运输\"')]\n"
     ]
    }
   ],
   "source": [
    "#输出主题结果\n",
    "print(lda.print_topics(num_topics=-1, num_words=5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "527c367c32f2ef9759f7fd3ae2281bdfc78f30903e7edd9cdbf6e60c32c97157"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tf24')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
