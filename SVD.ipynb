{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD(奇异值分解)  \n",
    "奇异值分解在机器学习中是一个很常见的矩阵分解算法，其目的是提取出一个矩阵最重要的特征。\n",
    "\n",
    "### 1、特征值、特征向量、特征值分解  \n",
    "#### 1）特征值、特征向量  \n",
    "如果一个向量$v$是矩阵A的特征向量，那么一定可以表示成如下的形式：  \n",
    "$$Av=\\lambda v$$  \n",
    "其中$\\lambda$是特征向量$v$的特征值，一个矩阵的一组特征向量是一组正交向量。\n",
    "\n",
    "#### 2）特征值和特征向量的几何意义  \n",
    "一个矩阵其实就是一个线性变换，因为一个矩阵乘以一个向量后得到向量，其实就相当于将这个向量进行了线性变换。比如说下面这个矩阵：\n",
    "$ M = \\begin{bmatrix}\n",
    "    3 & 0 \\\\\n",
    "    0 & 1\n",
    "\\end{bmatrix}$  \n",
    "它其实对应的线性变换形式为：  \n",
    "![矩阵M的线性变换](picture/SVD1.png)  \n",
    "矩阵M的线性变换  \n",
    "因为矩阵M乘以一个向量（X，Y）的结果是：  \n",
    "$$\\begin{bmatrix}\n",
    "    3 & 0 \\\\\n",
    "    0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    X \\\\\n",
    "    Y\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "    3X \\\\\n",
    "    Y\n",
    "\\end{bmatrix}$$  \n",
    "上面的矩阵是对称的，所以这个变换是一个对x、y轴的方向一个拉伸变换（每一个对角线上的元素将会对一个维度进行拉伸变换，当值大于1时是拉伸，当值小于1时是缩短），如图2所示。当矩阵不是对称的时候，假如说矩阵是下面的样子：  \n",
    "$$M = \\begin{bmatrix}\n",
    "    1 & 1 \\\\\n",
    "    0 & 1\n",
    "\\end{bmatrix}$$  \n",
    "它所描述的变换是下面这个样子的：  \n",
    "![M是非对称矩阵变换](picture/SVD2.png)  \n",
    "这其实是在平面上对一个轴进行的拉伸变换，如上图蓝色的箭头所示，蓝色的箭头是一个最主要的变换方向（变换的方向可能不止一个）。如果想要描述好一个变换，那我们就需要描述好这个变换主要的变化方向。  \n",
    "\n",
    "#### 3）特征值分解  \n",
    "对于矩阵A，有一组特征向量v，将这组向量进行正交化单位化，就能得到一组正交单位向量。特征值分解，就是将矩阵A分解为如下式：  \n",
    "$$A=Q\\Sigma Q^{-1}$$  \n",
    "其中，Q是矩阵A的特征向量组成的矩阵，$\\Sigma$则是一个对角阵，对角线上的元素就是特征值。分析一下上面特征值分解的式子，分解得到的Σ矩阵是一个对角矩阵，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变换方向（从主要的变化到次要的变化排列）。  \n",
    "当矩阵是高维的情况下，那么这个矩阵就是高维空间下的一个线性变换，这个线性变换可能没法通过图片来表示，但是可以想象，这个变换也同样有很多的变化方向，我们通过特征值分解得到的前N个特征向量，就对应了这个矩阵最主要的N个变化方向。我们利用这前N个变化方向，就可以近似这个矩阵变换。也就是之前说的：提取这个矩阵最重要的特征。  \n",
    "特征值分解可以得到特征值与特征向量，特征值表示的是这个特征到底有多么重要，而特征向量表示这个特征是什么，可以将每一个特征向量理解为一个线性的子空间，我们可以利用这些线性的子空间干很多事情。不过，特征值分解也有很多的局限，比如说变换的矩阵必须是方阵。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、SVD分解  \n",
    "#### 1）特征值分解矩阵的缺点  \n",
    "前面说了很多特征值、特征向量和特征值分解，而且基于以前学习的线性代数知识，利用特征值分解提取特征矩阵是一个容易理解且便于实现的方法。但是为什么还存在奇异值分解呢？特征值分解最大的问题是只能针对方阵，即n*n的矩阵。而在实际的应用中，我们分解的大部分都不是方阵。  \n",
    "#### 2）奇异值分解  \n",
    "奇异值分解是一个能适用于任意矩阵的一种分解的方法，对于任意矩阵A总是存在一个奇异值分解：  \n",
    "$$A=U\\Sigma V^T$$  \n",
    "假设A是一个m*n的矩阵，那么得到的U是一个m*m的方阵，U里面的正交向量被称为左奇异向量。Σ是一个m*n的矩阵，Σ除了对角线其它元素都为0，对角线上的元素称为奇异值。$V^T$是V的转置矩阵是一个n*n的矩阵，它里面的正交向量被称为右奇异向量。而且一般来讲，我们会将Σ的值按从大到小的顺序排列。上面的矩阵维度变化可以参考下图所示：  \n",
    "![SVD分解矩阵维度变化](picture/SVD3.png)  \n",
    "虽然上面奇异值分解等式成立，但是如何求左奇异向量、右奇异向量和奇异值？由上面的式子，我们是不知道如何拆分矩阵A的。但可以吧奇异值和特征值联系起来。  \n",
    "首先，我们用矩阵A的转置乘以A，得到一个方阵，用这样的方阵进行特征分解，得到的特征值和特征向量满足下面的等式：  \n",
    "$$(A^TA)v_i=\\lambda_i v_i$$  \n",
    "这里的$v_i$就是我们要求的右奇异向量。  \n",
    "其次，我们 用矩阵A乘以A的转置，得到一个方阵，用这样的方阵进行特征分解，得到的特征值和特征向量满足下面的等式：  \n",
    "$$(AA^T)u_i=\\lambda_i u_i$$  \n",
    "这里的$u_i$就是左奇异向量。  \n",
    "对于奇异值，有两种方法求解：\n",
    ">第一种：  \n",
    ">$$A=U\\Sigma V^T \\Rightarrow AV=U\\Sigma V^TV=U\\Sigma \\Rightarrow Av_i=u_i\\sigma_i \\Rightarrow \\sigma_i=\\frac{Av_i}{u_i}$$  \n",
    ">第二种：  \n",
    "先证明一下上面说的$A^TA$的特征向量组成的矩阵就是SVD中的V矩阵：  \n",
    ">$$A=U\\Sigma V^T \\Rightarrow A^T=V\\Sigma^TU^T \\Rightarrow A^TA=V\\Sigma^TU^TU\\Sigma V^T=V\\Sigma^2V^T(*)$$  \n",
    ">证明$AA^T$的特征向量组成的矩阵是SVD中的U矩阵的方法同理。  \n",
    "通过上面*式的证明，我们还可以看出，特征值矩阵等于奇异值矩阵的平方，也就是说特征值和奇异值满足如下关系：  \n",
    ">$$\\sigma_i=\\sqrt\\lambda_i$$  \n",
    ">这里的$\\sigma$就是奇异值，奇异值$\\sigma$跟特征值类似，在矩阵$\\Sigma$中也是从大到小排序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么，我们现在已经知道如何用奇异值分解，但是分解之后的矩阵维度并没有比之前的矩阵维度小多少，而且还要做两次矩阵的乘法，并且矩阵乘法的复杂度是$O(n^3)$，那奇异值分解是在干啥？  \n",
    "在奇异值分解矩阵中Σ里面的奇异值按从大到小的顺序排列，奇异值$\\sigma_i$从大到小的顺序减小的特别快。在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上。也就是说，剩下的90%甚至99%的奇异值几乎没有什么作用。因此，我们可以用前面r个大的奇异值来近似描述矩阵，于是奇异值分解公式可以写成如下：  \n",
    "$$A_{m*n}\\approx U_{m*r}\\Sigma_{r*r}V_{r*n}^T$$  \n",
    "其中r是一个远远小于m和n的数，右边的三个矩阵相乘的结果将会是一个接近A的矩阵。如果r越接近于n，则相乘的结果越接近于A。如果r的取值远远小于n，从计算机内存的角度来说，右边三个矩阵的存储内存要远远小于矩阵A的。所以在奇异值分解中r的取值很重要，就是在计算精度和时间空间之间做选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、SVD分解的应用 \n",
    "奇异值分解的应用有很多，比如：用SVD解PCA、潜在语言索引也依赖于SVD算法。可以说，SVD是矩阵分解、降维、压缩、特征学习的一个基础的工具，所以SVD在机器学习领域相当的重要。  \n",
    "#### 1）降维  \n",
    "通过奇异值分解的公式，我们可以很容易看出来，原来矩阵A的特征有n维。经过SVD分解后，可以用前r个非零奇异值对应的奇异向量表示矩阵A的主要特征，这样就把矩阵A进行了降维。  \n",
    "#### 2）压缩  \n",
    "通过奇异值分解的公式，我们可以看出来，矩阵A经过SVD分解后，要表示原来的大矩阵A，我们只需要存储U、Σ、V三个较小的矩阵即可。而这三个较小规模的矩阵占用内存上也是远远小于原有矩阵A的，这样SVD分解就起到了压缩的作用。  \n",
    "\n",
    "### 参考文献  \n",
    "https://mp.weixin.qq.com/s/Dv51K8JETakIKe5dPBAPVg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99658224e-17 1.00000000e+00 3.00000000e+00] \n",
      " [[ 5.77350269e-01 -7.07106781e-01  4.08248290e-01]\n",
      " [-5.77350269e-01 -7.58447699e-17  8.16496581e-01]\n",
      " [ 5.77350269e-01  7.07106781e-01  4.08248290e-01]]\n"
     ]
    }
   ],
   "source": [
    "#奇异值分解的python实现\n",
    "import numpy as np\n",
    "A = [[0,1],\n",
    "     [1,1],\n",
    "     [1,0]]\n",
    "A = np.array(A)\n",
    "#计算A*A^T的特征值和特征向量\n",
    "eigh_val1, eigh_u = np.linalg.eigh(A.dot(A.T))\n",
    "print(eigh_val1,'\\n',eigh_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.00000000e+00 1.00000000e+00 9.99658224e-17] \n",
      " [[ 4.08248290e-01 -7.07106781e-01  5.77350269e-01]\n",
      " [ 8.16496581e-01 -7.58447699e-17 -5.77350269e-01]\n",
      " [ 4.08248290e-01  7.07106781e-01  5.77350269e-01]]\n"
     ]
    }
   ],
   "source": [
    "#对特征值按照从大到小进行排序\n",
    "eigh_sort_idx = np.argsort(eigh_val1)[::-1]\n",
    "eigh_val1 = np.sort(eigh_val1)[::-1]\n",
    "#将特征值对应的特征向量也对应排好序\n",
    "eigh_u = eigh_u[:,eigh_sort_idx] #左奇异矩阵\n",
    "print(eigh_val1,'\\n',eigh_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.73205081e+00 1.00000000e+00 9.99829098e-09] [[ 7.07106781e-01  7.07106781e-01]\n",
      " [ 7.07106781e-01 -7.07106781e-01]\n",
      " [ 7.45058060e-09  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#奇异值\n",
    "eigh_val1 = np.sqrt(eigh_val1)\n",
    "#奇异值矩阵的逆\n",
    "eigh_val_inv = np.linalg.inv(np.diag(eigh_val1))\n",
    "#计算右奇异矩阵\n",
    "eigh_v = eigh_val_inv.dot((eigh_u.T)).dot(A)\n",
    "print(eigh_val1,eigh_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.24182870e-16, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.35187331e-16]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigh_u.dot(np.diag(eigh_val1).dot(eigh_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.08248290e-01  7.07106781e-01  5.77350269e-01]\n",
      " [-8.16496581e-01  7.45552182e-17 -5.77350269e-01]\n",
      " [-4.08248290e-01 -7.07106781e-01  5.77350269e-01]] \n",
      " [1.73205081 1.        ] \n",
      " [[-0.70710678 -0.70710678]\n",
      " [-0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "#SVD的numpy实现\n",
    "import numpy as np\n",
    "A = [[0,1],\n",
    "     [1,1],\n",
    "     [1,0]]\n",
    "A = np.array(A)\n",
    "ei_u,ei_val,ei_v = np.linalg.svd(A)\n",
    "print(ei_u,'\\n',ei_val,'\\n',ei_v)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "527c367c32f2ef9759f7fd3ae2281bdfc78f30903e7edd9cdbf6e60c32c97157"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tf24')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
